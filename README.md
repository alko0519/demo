# Work with Reports
Work with Reports in Cloud Reporting can be divided into 3 main stages
## 1. Creating objects in the database (in Reporting DB)
Objects in the database - that are the tables, needed for specific datamarts and reports. Datamart Builder uses the same DB where CDC streams the data from CloudOM, DPM, etc. In the same database and with the same schema (as agreed with the colleagues from the CDC Team) - the necessary tables are created. 
Cloud Reporting Team uses Cloud Builder & Deployer, and they also have special repository (`datamarts-ddl/ddl_scripts/`) where so far there is just one script for the first report - Flowthrough Report (flowthrough_order_report.sql). This script describes the logic for creating objects in the reporting database in the required schema. This sctipt creates target and intermediate tables, indexes and views. At this stage only the mentioned database objects are created (tables, views), which will be filled with data in the next steps.
## 2. Reports data processing (collection, calculation, storing)
Datamart Builder uses AirFlow for orchestration. Which operations performed there? - a special files named DAGs (DAG, Directed Acyclic Graph - is a collection of all the tasks you want to run, organized in a way that reflects their relationships and dependencies) were written for AirFlow and AirFlow executes these scripts with calculations. These DAGs also located in special git repository (`datamarts-engine/dags/sql/flowthrough_order_report/`). 
At this stage, AirFlow according to the schedule takes these scripts (actually, SQL-scripts), opens the tables with SOURCE data (raw data comes from directlty from CDC or normalized data after Apache NiFi Normailizer), once we talking about Flowthrough Report - that is tables with orders, incidents, categories, etc., takes the data from there, processes them in the necessary way (launching scripts to calculate complex metrics) and stores the results of these calculations into the tables prepared in step 1. More detailed, there are two tables within the Flowthrough Report. One table contains detailed data (dm_flowthrough_report_detailed) - this is a list of orders and their attributes that are reqired by business users: order_id, current order status, owner of this order, etc.
When this detailed table is populated, Airflow populates the aggregated table (dm_flowthrough_report_aggregated). And in this table KPIs are already considered - in this table data is aggregated by day, and certain KPIs are calculated for each day. Finally, after these two tables are filled in by AirFlow DAGs we may continue with the step 3
## 3. Reports presentation
For the reports presentation Cloud Reporting Team developed the special tool which has Apache Superset under the hood. Apache Superset is a system that provides reporting and data analysis features. Superset allows to save and export already prepared dashboards configuration, i.e. being once prepared, report configuration (Flowthrough Report) can be easily imported into a new environment. The configuration contains only a few environment-dependent parameters (SQLAlchemy URI for database access and credentials). This dashboard configuration is the set of configuration files, packed into the zip-archive and containing the database configuration (connection to specific DB), datasets configuration (specific tables(datamarts) or SQL queries) and data representation configuration(charts). 



